{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolov5_LPR_thread",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1h5DZdCah_6BezkycdQxoAgxA7IBdzTTr",
      "authorship_tag": "ABX9TyO+lRt6KY1NF+yY2IJj5Qaj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tund-hcmue/license_plate_recognition/blob/main/yolov5_LPR_thread.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BioDWPrnQwiY"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzMn7-jvRIWN"
      },
      "source": [
        "%cd yolov5/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywm3r6p3RNtC"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VKxhIyXRQSS"
      },
      "source": [
        "!mkdir -p runs/train/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgDsX89-RndL"
      },
      "source": [
        "%cp -rf /content/drive/MyDrive/model_lpr/ /content/yolov5/runs/train/ #lpr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOb8bJegRsSU"
      },
      "source": [
        "%cp -rf /content/drive/MyDrive/exp/ /content/yolov5/runs/train/ #lp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP5Jayn9Rus2"
      },
      "source": [
        "%cp /content/drive/MyDrive/models/char_classifier.h5 /content/yolov5/ #char"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c3NDSv6cpo-"
      },
      "source": [
        "# !apt install tesseract-ocr -y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stP5pD0Mcqj6"
      },
      "source": [
        "# !pip install pytesseract"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn9-C2J3q9kt"
      },
      "source": [
        "# %cp nums.zip /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTzS1qbVwyV1"
      },
      "source": [
        "# %cp /content/drive/MyDrive/bike_counter_10min.mp4 /content/yolov5/data/images/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hNIf-n_CkhF"
      },
      "source": [
        "# !zip -r nums.zip /content/yolov5/runs/nums/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyUqyPZ9P5Ey"
      },
      "source": [
        "import argparse\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "from numpy import random\n",
        "import random as rd\n",
        "from models.experimental import attempt_load\n",
        "from utils.datasets import LoadStreams, LoadImages\n",
        "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
        "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
        "from utils.plots import plot_one_box\n",
        "from utils.torch_utils import select_device, load_classifier, time_synchronized\n",
        "from termcolor import colored\n",
        "import threading\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "import math\n",
        "from google.colab.patches import cv2_imshow\n",
        "from queue import Queue\n",
        "# import pytesseract\n",
        "\n",
        "class LicensePlate():\n",
        "    \n",
        "    def __init__(self, source = 'data/images/',\n",
        "                 weights_lp = 'runs/train/exp/weights/best.pt', \n",
        "                 weights_lpr = 'runs/train/model_lpr/weights/best.pt', \n",
        "                 img_size = 480, imglpr_size = 96, name = 'exp', \n",
        "                 project = 'runs/detect', device = '', \n",
        "                 conf_thres = float(0.25), conf_thres01 = float(0.25), \n",
        "                 iou_thres = float(0.45), save_txt = True, \n",
        "                 view_img = False, save_conf = False, \n",
        "                 classes = None, agnostic_nms = False, \n",
        "                 augment = False, update = False, exist_ok = False, \n",
        "                 save_img=False, nosave = True):\n",
        "        self.source = source\n",
        "        self.weights_lp = weights_lp\n",
        "        self.weights_lpr = weights_lpr\n",
        "        self.view_img = view_img\n",
        "        self.save_txt = save_txt\n",
        "        self.img_size = img_size\n",
        "        self.imglpr_size = imglpr_size\n",
        "        self.name = name\n",
        "        self.project = project\n",
        "        self.device = device\n",
        "        self.conf_thres = conf_thres\n",
        "        self.conf_thres01 = conf_thres01\n",
        "        self.iou_thres = iou_thres\n",
        "        self.exist_ok = exist_ok\n",
        "        self.augment = augment\n",
        "        self.classes = classes\n",
        "        self.agnostic_nms = agnostic_nms\n",
        "        self.save_conf = save_conf\n",
        "        self.save_img=save_img\n",
        "        self.update = update\n",
        "        self.nosave = nosave\n",
        "        self.img_plate = Queue()\n",
        "        self.lst_number = Queue()\n",
        "        self.plate_num = ''\n",
        "        self.img_number = None\n",
        "        \n",
        "        self.model_char = load_model(\"/content/yolov5/char_classifier.h5\")\n",
        "\n",
        "        t0 = time.time()\n",
        "        self.t1 = threading.Thread(name = \"t1\", target=self.detect, args = ())\n",
        "        self.t2 = threading.Thread(name = \"t2\", target=self.recognition, args = ())\n",
        "        self.t3 = threading.Thread(name = \"t3\", target=self.read_char, args = ())\n",
        "        \n",
        "        self.t1.start()\n",
        "        self.t2.start()\n",
        "        self.t3.start()\n",
        "        \n",
        "        self.t1.join()\n",
        "        self.t2.join()\n",
        "        self.t3.join()\n",
        "        print(f'Done. ({time.time() - t0:.3f}s)')\n",
        "\n",
        "    def crop_img(self, xywh, im0):     #detect and crop plate\n",
        "        width = im0.shape[1]\n",
        "        height = im0.shape[0]\n",
        "        x = xywh[0]\n",
        "        y = xywh[1]\n",
        "        w = xywh[2]\n",
        "        h = xywh[3]\n",
        "        xmin = int((x - w/2)*width)\n",
        "        ymin = int((y - h/2)*height)\n",
        "        xmax = int(xmin + (w*width))\n",
        "        ymax = int(ymin + (h*height))\n",
        "        \n",
        "        cropped = im0[ymin:ymax, xmin:xmax]\n",
        "        # height_lp, width_lp, cn = cropped.shape\n",
        "        # height_new = int(190/(width_lp/float(height_lp)))\n",
        "        # lp = cv2.resize(cropped, (190, 140), interpolation = cv2.INTER_CUBIC)\n",
        "                \n",
        "        return cropped\n",
        "    def rotate_image(self, image):\n",
        "        # lines = []\n",
        "        h, w = image.shape[:2]\n",
        "\n",
        "        img = cv2.medianBlur(image, 3)\n",
        "\n",
        "        edges = cv2.Canny(img,  threshold1 = 30,  threshold2 = 100, apertureSize = 3, L2gradient = True)\n",
        "        lines = cv2.HoughLinesP(edges, 1, math.pi/180, 30, minLineLength=w / 4.0, maxLineGap=h/4.0)\n",
        "        angle = 0.0\n",
        "        # nlines = lines.size\n",
        "\n",
        "        #print(nlines)\n",
        "        cnt = 0\n",
        "        \n",
        "        if lines is not None:\n",
        "            for x1, y1, x2, y2 in lines[0]:\n",
        "                ang = np.arctan2(y2 - y1, x2 - x1)\n",
        "                #print(ang)\n",
        "                if math.fabs(ang) <= 30: # excluding extreme rotations\n",
        "                    angle += ang\n",
        "                    cnt += 1\n",
        "\n",
        "            if cnt == 0:\n",
        "                return 0.0\n",
        "            angle = (angle / cnt)*180/math.pi\n",
        "        if abs(angle) > float(30):\n",
        "            pos = (True if angle < 0 else False)\n",
        "            angle = 90 - abs(angle)\n",
        "            angle = (angle*(-1) if pos else angle)\n",
        "\n",
        "        image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "        rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "        result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "        return result\n",
        "    \n",
        "\n",
        "    def letterbox(self, img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n",
        "        # Resize and pad image while meeting stride-multiple constraints\n",
        "        shape = img.shape[:2]  # current shape [height, width]\n",
        "        if isinstance(new_shape, int):\n",
        "            new_shape = (new_shape, new_shape)\n",
        "\n",
        "        # Scale ratio (new / old)\n",
        "        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
        "        if not scaleup:  # only scale down, do not scale up (for better test mAP)\n",
        "            r = min(r, 1.0)\n",
        "\n",
        "        # Compute padding\n",
        "        ratio = r, r  # width, height ratios\n",
        "        new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
        "        dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
        "        if auto:  # minimum rectangle\n",
        "            dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
        "        elif scaleFill:  # stretch\n",
        "            dw, dh = 0.0, 0.0\n",
        "            new_unpad = (new_shape[1], new_shape[0])\n",
        "            ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n",
        "\n",
        "        dw /= 2  # divide padding into 2 sides\n",
        "        dh /= 2\n",
        "\n",
        "        if shape[::-1] != new_unpad:  # resize\n",
        "            img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
        "        top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
        "        left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
        "        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
        "        return img, ratio, (dw, dh)\n",
        "    def BGR_to_thr(self, img):\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        gray = cv2.resize( gray, (28, 28), 0, 0,interpolation = cv2.INTER_CUBIC)\n",
        "        \n",
        "        ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
        "\n",
        "        # roi = cv2.bitwise_not(thresh)\n",
        "        roi = cv2.medianBlur(thresh, 3)\n",
        "\n",
        "        return roi\n",
        "    def read_char(self):\n",
        "        char_list =  '0123456789ABCDEFGHKLMNPSTUVXYZ'\n",
        "        while 1:\n",
        "            plate_num = ''\n",
        "            lst_number = self.lst_number.get()\n",
        "            if lst_number is None:\n",
        "                break\n",
        "            else:\n",
        "                if (len(lst_number) >5):\n",
        "                    for lpr in lst_number:\n",
        "\n",
        "                        # x = image.img_to_array(img)\n",
        "                        backtorgb = cv2.cvtColor(lpr,cv2.COLOR_GRAY2RGB)\n",
        "                        x = np.array(backtorgb)\n",
        "                        x = np.expand_dims(x, axis=0)\n",
        "\n",
        "                        images = np.vstack([x])\n",
        "                        classes = self.model_char.predict_classes(images)\n",
        "\n",
        "                        lp = char_list[classes[0]]\n",
        "                        plate_num += lp\n",
        "                else:\n",
        "                    plate_num += 'None'\n",
        "            print(colored(\"\\n Number Plate :\", \"red\"), plate_num)\n",
        "    def recognition(self):\n",
        "        source, weights, view_img, save_txt, imgsz = self.source, self.weights_lpr, self.view_img, self.save_txt, self.imglpr_size\n",
        "        webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(\n",
        "            ('rtsp://', 'rtmp://', 'http://'))\n",
        "\n",
        "        # Directories\n",
        "        save_dir = Path(increment_path(Path(self.project) / self.name, exist_ok=self.exist_ok))  # increment run\n",
        "        (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
        "\n",
        "        # Initialize\n",
        "        set_logging()\n",
        "        device = select_device(self.device)\n",
        "        half = device.type != 'cpu'  # half precision only supported on CUDA\n",
        "\n",
        "        # Load modelim0s\n",
        "        model = attempt_load(weights, map_location=device)  # load FP32 model\n",
        "        stride = int(model.stride.max())  # model striderecognition\n",
        "        imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
        "        if half:\n",
        "            model.half()  # to FP16\n",
        "\n",
        "        # Second-stage classifier\n",
        "        classify = False\n",
        "        if classify:\n",
        "            modelc = load_classifier(name='resnet101', n=2)  # initialize\n",
        "            modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()\n",
        "\n",
        "        # Set Dataloader\n",
        "        vid_path, vid_writer = None, None\n",
        "        if webcam:\n",
        "            view_img = check_imshow()\n",
        "            cudnn.benchmark = True  # set True to speed up constant image size inference\n",
        "            dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n",
        "        else:\n",
        "            save_img = True\n",
        "            dataset = LoadImages(source, img_size=imgsz, stride=stride)\n",
        "\n",
        "        # Get names and colors\n",
        "        names = model.module.names if hasattr(model, 'module') else model.names\n",
        "        colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
        "\n",
        "        # Run inference\n",
        "        if device.type != 'cpu':\n",
        "            model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
        "        t0 = time.time()\n",
        "        while 1:\n",
        "            detect_lp = self.img_plate.get()\n",
        "            if (detect_lp is None):\n",
        "                break\n",
        "            for lp in detect_lp:\n",
        "                lp = cv2.resize(lp, (190, 140), interpolation = cv2.INTER_CUBIC)\n",
        "                \n",
        "                # for path, img, im0s, vid_cap in dataset:\n",
        "                img = self.letterbox(lp, 192, stride=32)[0]                      \n",
        "\n",
        "                # Convert\n",
        "                img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
        "                img = np.ascontiguousarray(img)\n",
        "\n",
        "                img = torch.from_numpy(img).to(device)\n",
        "                \n",
        "                img = img.half() if half else img.float()  # uint8 to fp16/32\n",
        "                \n",
        "                img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "                \n",
        "                if img.ndimension() == 3:\n",
        "                    img = img.unsqueeze(0)\n",
        "                im0s = lp\n",
        "                \n",
        "                # Inference\n",
        "                t1 = time_synchronized()\n",
        "                pred = model(img, augment=self.augment)[0]\n",
        "\n",
        "                # Apply NMS\n",
        "                pred = non_max_suppression(pred, self.conf_thres01, self.iou_thres, classes=self.classes, agnostic=self.agnostic_nms)\n",
        "                t2 = time_synchronized()\n",
        "                \n",
        "                # Apply Classifier\n",
        "                if classify:\n",
        "                    pred = apply_classifier(pred, modelc, img, im0s)\n",
        "                    \n",
        "                # Process detections\n",
        "                for i, det in enumerate(pred):  # detections per image\n",
        "                    im0 = im0s\n",
        "                    # det = det[det[:,3].sort()[1]]\n",
        "                    lst = det.tolist()\n",
        "                    \n",
        "                    sortt = sorted(lst, key = lambda x: x[1], reverse=True)\n",
        "                    # index = self.getCol(lst, 2)\n",
        "                    index = math.ceil(len(lst)/float(2))\n",
        "                    \n",
        "\n",
        "                    sortt1 = sorted(sortt[:index], key = lambda x: x[3])\n",
        "                    sortt2 = sorted(sortt[index:], key = lambda x: x[3])\n",
        "\n",
        "                    det = torch.tensor(sortt1+sortt2)\n",
        "                    \n",
        "                    gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "                    \n",
        "                    if len(det):\n",
        "                        # Rescale boxes from img_size to im0 size\n",
        "                        det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
        "                        \n",
        "                        # Write results\n",
        "                        lst_number = []\n",
        "                        plate_num = ''\n",
        "                        for *xyxy, conf, cls in reversed(det):\n",
        "                            \n",
        "                            if (float(f' {conf:.2f}') > 0.5):\n",
        "                                xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
        "                                \n",
        "                                x = xywh[0]\n",
        "                                y = xywh[1]\n",
        "                                w = xywh[2]\n",
        "                                h = xywh[3]\n",
        "                                # print(f' {conf:.2f}')\n",
        "                                try:\n",
        "                                    img_number = self.crop_img(xywh, im0)\n",
        "                                    img_number = self.BGR_to_thr(img_number)\n",
        "                                except:\n",
        "                                    pass\n",
        "\n",
        "                                lst_number.append(img_number)\n",
        "                                \n",
        "                                label = f'. {conf:.2f}'\n",
        "                                plot_one_box(xyxy, lp, label=label, color=colors[int(cls)], line_thickness=1)\n",
        "                            else:\n",
        "                                pass\n",
        "                        self.lst_number.put(lst_number)\n",
        "                \n",
        "        self.lst_number.put(None)\n",
        "\n",
        "    def detect(self):\n",
        "        source, weights, view_img, save_txt, imgsz = self.source, self.weights_lp, self.view_img, self.save_txt, self.img_size\n",
        "        save_img = not self.nosave and not source.endswith('.txt')  # save inference images\n",
        "        webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(\n",
        "            ('rtsp://', 'rtmp://', 'http://'))\n",
        "\n",
        "        # Directories\n",
        "        save_dir = Path(increment_path(Path(self.project) / self.name, exist_ok=self.exist_ok))  # increment run\n",
        "        (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
        "\n",
        "        # Initialize\n",
        "        set_logging()\n",
        "        device = select_device(self.device)\n",
        "        half = device.type != 'cpu'  # half precision only supported on CUDA\n",
        "\n",
        "        # Load model\n",
        "        model = attempt_load(weights, map_location=device)  # load FP32 model\n",
        "        stride = int(model.stride.max())  # model stride\n",
        "        imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
        "        if half:\n",
        "            model.half()  # to FP16\n",
        "\n",
        "        # Second-stage classifier\n",
        "        classify = False\n",
        "        if classify:\n",
        "            modelc = load_classifier(name='resnet101', n=2)  # initialize\n",
        "            modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()\n",
        "\n",
        "        # Set Dataloader\n",
        "        vid_path, vid_writer = None, None\n",
        "        if webcam:\n",
        "            view_img = check_imshow()\n",
        "            cudnn.benchmark = True  # set True to speed up constant image size inference\n",
        "            dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n",
        "        else:\n",
        "            save_img = True\n",
        "            dataset = LoadImages(source, img_size=imgsz, stride=stride)\n",
        "\n",
        "        # Get names and colors\n",
        "        names = model.module.names if hasattr(model, 'module') else model.names\n",
        "        colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
        "\n",
        "        # Run inference\n",
        "        if device.type != 'cpu':\n",
        "            model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
        "        t0 = time.time()\n",
        "        for path, img, im0s, vid_cap in dataset:\n",
        "            img = torch.from_numpy(img).to(device)\n",
        "            img = img.half() if half else img.float()  # uint8 to fp16/32\n",
        "            img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "            if img.ndimension() == 3:\n",
        "                img = img.unsqueeze(0)\n",
        "\n",
        "            # Inference\n",
        "            t1 = time_synchronized()\n",
        "            pred = model(img, augment=self.augment)[0]\n",
        "\n",
        "            # Apply NMS\n",
        "            pred = non_max_suppression(pred, self.conf_thres, self.iou_thres, classes=self.classes, agnostic=self.agnostic_nms)\n",
        "            t2 = time_synchronized()\n",
        "\n",
        "            # Apply Classifier\n",
        "            if classify:\n",
        "                pred = apply_classifier(pred, modelc, img, im0s)\n",
        "\n",
        "            # Process detections\n",
        "            for i, det in enumerate(pred):  # detections per image\n",
        "                if webcam:  # batch_size >= 1\n",
        "                    p, s, im0, frame = path[i], '%g: ' % i, im0s[i].copy(), dataset.count\n",
        "                else:\n",
        "                    p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)\n",
        "\n",
        "                p = Path(p)  # to Path\n",
        "                save_path = str(save_dir / p.name)  # img.jpg\n",
        "                txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # img.txt\n",
        "                s += '%gx%g ' % img.shape[2:]  # print string\n",
        "                gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "                if len(det):\n",
        "                    # Rescale boxes from img_size to im0 size\n",
        "                    det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
        "\n",
        "                    # Print results\n",
        "                    for c in det[:, -1].unique():\n",
        "                        n = (det[:, -1] == c).sum()  # detections per class\n",
        "                        s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
        "\n",
        "                    # Write results\n",
        "                    lst_plate = []\n",
        "                    for *xyxy, conf, cls in reversed(det):\n",
        "                        if save_txt:  # Write to file\n",
        "                            xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
        "                            \n",
        "                            x = xywh[0]\n",
        "                            y = xywh[1]\n",
        "                            w = xywh[2]\n",
        "                            h = xywh[3]\n",
        "\n",
        "                            img_plate = self.crop_img(xywh, im0)\n",
        "                            img_rotate = self.rotate_image(img_plate)\n",
        "                            # cv2.imwrite(save_path, img_rotate)\n",
        "                            lst_plate.append(img_rotate)\n",
        "\n",
        "                        if save_img or view_img:  # Add bbox to image\n",
        "                            # label = f'{names[int(cls)]} {conf:.2f}'\n",
        "                            label = f'Plate {conf:.2f}'\n",
        "                            plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=3)\n",
        "                    self.img_plate.put(lst_plate)\n",
        "\n",
        "                # Stream results\n",
        "                if view_img:\n",
        "                    cv2.imshow(str(p), im0)\n",
        "                    cv2.waitKey(1)  # 1 millisecond\n",
        "\n",
        "                # Save results (image with detections)\n",
        "                if save_img:\n",
        "                    if dataset.mode == 'image':\n",
        "                        cv2.imwrite(save_path, im0)\n",
        "                        # print(\"save_path\")\n",
        "                    else:  # 'video' or 'stream'\n",
        "                        if vid_path != save_path:  # new video\n",
        "                            vid_path = save_path\n",
        "                            if isinstance(vid_writer, cv2.VideoWriter):\n",
        "                                vid_writer.release()  # release previous video writer\n",
        "                            if vid_cap:  # videoyolov5/runs/train/exp/\n",
        "                                fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
        "                                w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "                                h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "                            else:  # stream\n",
        "                                fps, w, h = 30, im0.shape[1], im0.shape[0]\n",
        "                                save_path += '.mp4'\n",
        "                            vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
        "                        vid_writer.write(im0)\n",
        "\n",
        "        self.img_plate.put(None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwBHOrYqTAA2"
      },
      "source": [
        "t = LicensePlate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d89Va_FBeVRa"
      },
      "source": [
        "!rm -rf runs/detect/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGHOtz3fy7-4",
        "cellView": "form"
      },
      "source": [
        "#@title Search file\n",
        "import os\n",
        "for rot, a, file in os.walk(\"/content/yolov5/runs/detect/\"):\n",
        "    for f in file:\n",
        "        if f.endswith(\".mp4\"):\n",
        "            print(os.path.abspath(f))\n",
        "            print(rot)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}